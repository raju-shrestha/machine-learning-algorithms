{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tf-idf stands for term frequency-inverse document frequency, and the tf-idf weight is a weight often used in information retrieval and text mining. \n",
    "This weight is a statistical measure used to evaluate how important a word is to a document in a collection or corpus.\n",
    "\n",
    "http://www.tfidf.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 20news dataset. This may take a few minutes.\n",
      "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
     ]
    }
   ],
   "source": [
    "# Importing dataset directly from Internet using sklearn library\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "categories = ['alt.atheism', 'soc.religion.christian','comp.graphics', 'sci.med']\n",
    "news_train = fetch_20newsgroups(subset ='train', categories= categories, shuffle = True)\n",
    "news_test = fetch_20newsgroups(subset ='test',categories= categories, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR', 'description'])\n"
     ]
    }
   ],
   "source": [
    "print(news_train.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism', 'comp.graphics', 'sci.med', 'soc.religion.christian']\n"
     ]
    }
   ],
   "source": [
    "print(news_train['target_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism', 'comp.graphics', 'sci.med', 'soc.religion.christian']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_train.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Count - CountVectorizer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count the occurance of each word, basically encoding documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo code to understand CountVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print Vocabulary:{'the': 7, 'quick': 6, 'brown': 0, 'fox': 2, 'jumped': 3, 'over': 5, 'lazy': 4, 'dog': 1}\n",
      "\n",
      "\n",
      "Feature names: ['brown', 'dog', 'fox', 'jumped', 'lazy', 'over', 'quick', 'the']\n",
      "\n",
      "\n",
      "The shape of count is: (3, 8)\n",
      "\n",
      "\n",
      "Printing count: \n",
      "[[1 1 1 1 1 1 1 2]\n",
      " [0 1 0 0 0 0 0 1]\n",
      " [0 0 1 0 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "text = [\"The quick brown fox jumped over the lazy dog.\",\n",
    "    \"The dog.\",\n",
    "    \"The fox.\"]\n",
    "\n",
    "# Assign a unique number to each word as: also known as \"Tokenize\"\n",
    "vector = CountVectorizer()\n",
    "vector.fit(text)\n",
    "\n",
    "# Learn a vocabulary dictionary of all tokens in the raw documents.\n",
    "print(\"Print Vocabulary:\"+str(vector.vocabulary_)+'\\n\\n')\n",
    "\n",
    "vector.get_feature_names()\n",
    "print(\"Feature names: \"+str(vector.get_feature_names())+'\\n\\n')\n",
    "\n",
    "counts = vector.transform(text)\n",
    "print(\"The shape of count is: \"+str(counts.shape)+'\\n\\n')\n",
    "# Only 1 sample space and it has 8 features\n",
    "print(\"Printing count: \"+'\\n'+str(counts.toarray()))\n",
    "      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning frequency of all features:[1.69314718 1.28768207 1.28768207 1.69314718 1.69314718 1.69314718\n",
      " 1.69314718 1.        ]\n",
      "\n",
      "\n",
      "Transfroming the matrix based on the learnt frequencies or weight:\n",
      "\n",
      "[[0.36388646 0.27674503 0.27674503 0.36388646 0.36388646 0.36388646\n",
      "  0.36388646 0.42983441]\n",
      " [0.         0.78980693 0.         0.         0.         0.\n",
      "  0.         0.61335554]\n",
      " [0.         0.         0.78980693 0.         0.         0.\n",
      "  0.         0.61335554]]\n"
     ]
    }
   ],
   "source": [
    "# Demo code to understand TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "# Create the transformer\n",
    "vectorizer = TfidfTransformer()\n",
    "vectorizer.fit(counts)\n",
    "print('Learning frequency of all features:'+str(vectorizer.idf_)+'\\n\\n')\n",
    "\n",
    "freq = vectorizer.transform(counts)\n",
    "print('Transfroming the matrix based on the learnt frequencies or weight:\\n\\n'+str(freq.toarray()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2257, 35788)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Word Count-CountVectorize -> Count the occurance of each word, basically encoding documents\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_tf = count_vect.fit_transform(news_train.data)\n",
    "X_train_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2257, 35788)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_tf)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(X_train_tfidf, news_train.target)\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_new = ['God is love', 'OpenGL on the GPU is fast']\n",
    "X_new_counts = count_vect.transform(docs_new) # fit is used for learning which is already used before so here transform is \n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "predicted = clf.predict(X_new_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for x in predicted:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism', 'comp.graphics', 'sci.med', 'soc.religion.christian']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_train.target_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tf = count_vect.transform(news_test.data)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_tf)\n",
    "predicted = clf.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8348868175765646\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.97      0.60      0.74       319\n",
      "         comp.graphics       0.96      0.89      0.92       389\n",
      "               sci.med       0.97      0.81      0.88       396\n",
      "soc.religion.christian       0.65      0.99      0.78       398\n",
      "\n",
      "           avg / total       0.88      0.83      0.84      1502\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, array([[192,   2,   6, 119],\n",
       "        [  2, 347,   4,  36],\n",
       "        [  2,  11, 322,  61],\n",
       "        [  2,   2,   1, 393]], dtype=int64))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy:\", accuracy_score(news_test.target, predicted))\n",
    "print(metrics.classification_report(news_test.target, predicted, target_names = news_test.target_names)), metrics.confusion_matrix(news_test.target, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.50      1.00      0.67         1\n",
      "    class 1       0.00      0.00      0.00         1\n",
      "    class 2       1.00      0.67      0.80         3\n",
      "\n",
      "avg / total       0.70      0.60      0.61         5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_true = [0,1,2,2,2]\n",
    "y_pred = [0,0,2,2,1] \n",
    "target_names = ['class 0','class 1', 'class 2']\n",
    "print(classification_report(y_true, y_pred, target_names =target_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 2]], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision = No. of correct result/No. of total returned result\n",
    "# Recall = No. of correct result/No. of correct result that should have been returned\n",
    "# F1 score = 2* (precision * recall)/(precision + recall)\n",
    "# MIcro-avg = Total no. of correct result/Total no. of returned result\n",
    "# Macro-avg = Add all precision values/Total no. of labels\n",
    "# Weighted-avg = (Sum of precision of each label * support of each label)/ Total no. of support\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Magic-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count Vectorizer(word count) + TDIDF Transformer (frequency) ->TDIDF Vectorizer\n",
    "# TDIDF Vectorizer does both word count & frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Magic-2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TDIDF Vectorizer + MultiNomial NB => Create Pipeline\n",
    "We create pipeline of TDIDF Vectorizer, MultiNomial NB  & encapsulate it into object 'a'. And, perform operation with object 'a' of pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
